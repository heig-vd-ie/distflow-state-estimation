{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from polars import col as c\n",
    "import networkx as nx\n",
    "\n",
    "from config import settings\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, UTC\n",
    "import datetime as dt\n",
    "\n",
    "from utility.polars_operation import generate_uuid_col\n",
    "from utility.parser_utility import (\n",
    "    add_table_to_changes_schema,\n",
    "    generate_connectivity_table,\n",
    "    generate_random_uuid,\n",
    ")\n",
    "from utility.general_function import pl_to_dict\n",
    "\n",
    "from twindigrid_changes.schema import ChangesSchema\n",
    "from twindigrid_sql.schema.enum import (\n",
    "    MeasurementClass,\n",
    "    MeasurementPhase,\n",
    "    MeasurementColumn,\n",
    "    SubstationType,\n",
    "    TerminalSide,\n",
    ")\n",
    "from twindigrid_sql.entries.source import (\n",
    "    SCADA,\n",
    "    CONVENTIONAL_METER,\n",
    "    GRID_LOAD,\n",
    "    SCADA,\n",
    "    ESTIMATED,\n",
    ")\n",
    "\n",
    "\n",
    "from twindigrid_sql.entries.equipment_class import (\n",
    "    TRANSFORMER,\n",
    "    BRANCH,\n",
    "    SWITCH,\n",
    "    INDIRECT_FEEDER,\n",
    "    BUSBAR_SECTION,\n",
    "    ENERGY_CONSUMER,\n",
    ")\n",
    "from twindigrid_sql.entries.measurement_type import ENERGY, ACTIVE_POWER, REACTIVE_POWER\n",
    "from twindigrid_sql.entries.unit_symbol import WATTHOUR, WATT\n",
    "\n",
    "# Useless outside jupiternotebook because in settings.py a line that changes the directory to src for ipynb\n",
    "os.chdir(os.getcwd().replace(\"/src\", \"\"))\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names: dict[str, str] = json.load(open(settings.INPUT_FILE_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (58, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>indexLines_1</th><th>indexLines_2</th><th>indexLines_3</th><th>Vnom</th><th>Snom</th><th>powerFactor_1</th><th>powerFactor_2</th><th>Bnode</th><th>SM</th><th>Annual</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>0.0</td></tr><tr><td>1</td><td>4</td><td>5</td><td>null</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>0.0</td></tr><tr><td>2</td><td>6</td><td>7</td><td>8</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>0.0</td></tr><tr><td>3</td><td>9</td><td>null</td><td>null</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>0.0</td></tr><tr><td>4</td><td>null</td><td>null</td><td>null</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>12.0</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>53</td><td>null</td><td>null</td><td>null</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>3095.956989</td></tr><tr><td>54</td><td>55</td><td>56</td><td>null</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>0.0</td></tr><tr><td>55</td><td>57</td><td>null</td><td>null</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>0.0</td></tr><tr><td>56</td><td>null</td><td>null</td><td>null</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>3452.129032</td></tr><tr><td>57</td><td>null</td><td>null</td><td>null</td><td>400</td><td>null</td><td>0.8</td><td>1</td><td>0</td><td>NaN</td><td>7921.285319</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (58, 11)\n",
       "┌───────┬──────────────┬──────────────┬─────────────┬───┬─────────────┬───────┬──────┬─────────────┐\n",
       "│ index ┆ indexLines_1 ┆ indexLines_2 ┆ indexLines_ ┆ … ┆ powerFactor ┆ Bnode ┆ SM   ┆ Annual      │\n",
       "│ ---   ┆ ---          ┆ ---          ┆ 3           ┆   ┆ _2          ┆ ---   ┆ ---  ┆ ---         │\n",
       "│ i64   ┆ i64          ┆ i64          ┆ ---         ┆   ┆ ---         ┆ i64   ┆ f64  ┆ f64         │\n",
       "│       ┆              ┆              ┆ i64         ┆   ┆ i64         ┆       ┆      ┆             │\n",
       "╞═══════╪══════════════╪══════════════╪═════════════╪═══╪═════════════╪═══════╪══════╪═════════════╡\n",
       "│ 0     ┆ 1            ┆ 2            ┆ 3           ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 0.0         │\n",
       "│ 1     ┆ 4            ┆ 5            ┆ null        ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 0.0         │\n",
       "│ 2     ┆ 6            ┆ 7            ┆ 8           ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 0.0         │\n",
       "│ 3     ┆ 9            ┆ null         ┆ null        ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 0.0         │\n",
       "│ 4     ┆ null         ┆ null         ┆ null        ┆ … ┆ 1           ┆ 0     ┆ 12.0 ┆ 0.0         │\n",
       "│ …     ┆ …            ┆ …            ┆ …           ┆ … ┆ …           ┆ …     ┆ …    ┆ …           │\n",
       "│ 53    ┆ null         ┆ null         ┆ null        ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 3095.956989 │\n",
       "│ 54    ┆ 55           ┆ 56           ┆ null        ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 0.0         │\n",
       "│ 55    ┆ 57           ┆ null         ┆ null        ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 0.0         │\n",
       "│ 56    ┆ null         ┆ null         ┆ null        ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 3452.129032 │\n",
       "│ 57    ┆ null         ┆ null         ┆ null        ┆ … ┆ 1           ┆ 0     ┆ NaN  ┆ 7921.285319 │\n",
       "└───────┴──────────────┴──────────────┴─────────────┴───┴─────────────┴───────┴──────┴─────────────┘"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_distflow: pl.DataFrame = pl.read_csv(file_names[\"Distflow_parameter\"])\n",
    "nodedata_distflow: pl.DataFrame = pl.read_csv(file_names[\"Distflow_node_data\"])\n",
    "powerdata_distflow: pl.DataFrame = pl.read_csv(file_names[\"Distflow_Power_data\"])\n",
    "linedata_distflow: pl.DataFrame = pl.read_csv(file_names[\"Distflow_Line_data\"])\n",
    "result_distflow: pl.DataFrame = pl.read_csv(file_names[\"Distflow_result\"])\n",
    "# nodedata_distflow = nodedata_distflow.with_columns(c(\"Snom\").cast(pl.Int8))\n",
    "# # To have base value (need lenght of line), not from matlab !\n",
    "# line_data_from_input_file: pl.DataFrame = pl.read_excel(\n",
    "#     file_names[\"Line_Data_From_Input_File\"]\n",
    "# )\n",
    "\n",
    "# Add node number to power data\n",
    "powerdata_distflow = powerdata_distflow.with_row_index(\n",
    "    \"node_number\", offset=1\n",
    ")  # offset=1 because slack bus is 0 and no power on it\n",
    "powerdata_distflow = powerdata_distflow.with_columns(c(\"node_number\").cast(pl.Int64))\n",
    "# Create a topology dataframe with basic topology information\n",
    "\n",
    "df_topology = nodedata_distflow.select(\n",
    "    c(\"index\").alias(\"node_number\"),\n",
    "    c(\"Vnom\"),\n",
    ")\n",
    "\n",
    "# Add the power data to the topology dataframe with node as key\n",
    "df_topology = df_topology.join(\n",
    "    powerdata_distflow, on=\"node_number\", how=\"full\", coalesce=True\n",
    ")\n",
    "nodedata_distflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set missing value for equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set missing value for equipment\n",
    "# Fake value for the length of the branch\n",
    "base_length = 1\n",
    "# Fake value for the switch state\n",
    "switch_state = False\n",
    "switch_type = \"locked_switch\"\n",
    "switch_command = \"unknown\"\n",
    "\n",
    "# Initialisation\n",
    "default_install_date: datetime = datetime(*settings.DEFAULT_INSTALL_DATE, tzinfo=UTC)\n",
    "heartbeat = datetime.now(UTC)\n",
    "changes_schema = ChangesSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectivity node table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the node dict with uuid for each node\n",
    "connectivity_node: dict[float, str] = pl_to_dict(\n",
    "    df_topology.select(\n",
    "        c(\"node_number\"),\n",
    "        c(\"node_number\").pipe(generate_uuid_col, added_string=\"node_\").alias(\"uuid\"),\n",
    "    )\n",
    ")\n",
    "## Add the cn_fk to the topology dataframe\n",
    "df_topology = df_topology.with_columns(\n",
    "    c(\"node_number\").replace_strict(connectivity_node, default=None).alias(\"cn_fk\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# branch :pl.DataFrame =\n",
    "\n",
    "\n",
    "# Current and other line parameter in pu\n",
    "\n",
    "# Filter to take only branch, connection_type == 2\n",
    "branch = linedata_distflow.filter(c(\"connection_type\") == 2).select(\n",
    "    (\"line_\" + c(\"line_number\").cast(pl.String)).alias(\"dso_code\"),\n",
    "    c(\"i_pu\").alias(\"current_limit\"),\n",
    "    c(\"r_pu\"),\n",
    "    c(\"x_pu\"),\n",
    "    c(\"b_pu\"),\n",
    "    # Need column name non null value for validation of the schema\n",
    "    pl.lit(base_length).alias(\"length\"),  # km\n",
    "    pl.lit(BRANCH).alias(\"concrete_class\"),\n",
    "    pl.lit(default_install_date).alias(\"start\"),\n",
    "    pl.lit(heartbeat).alias(\"start_heartbeat\"),\n",
    "    c(\"line_number\").pipe(generate_uuid_col, added_string=BRANCH).alias(\"uuid\"),\n",
    "    # Generate uuid for each terminal of branch with node uuid\n",
    "    c(\"node_from\").replace_strict(connectivity_node, default=None).alias(\"t1\"),\n",
    "    c(\"node_to\").replace_strict(connectivity_node, default=None).alias(\"t2\"),\n",
    "    # Need column name for validation of the schema\n",
    "    pl.lit(None).alias(\"t1_container_fk\"),\n",
    "    pl.lit(None).alias(\"t2_container_fk\"),\n",
    ")\n",
    "branch_parameter_event: pl.DataFrame = branch.with_columns(\n",
    "    c(\"uuid\").alias(\"eq_fk\"),\n",
    "    c(\"uuid\").pipe(generate_random_uuid).alias(\"uuid\"),\n",
    "    c(\"r_pu\").alias(\"r\"),\n",
    "    c(\"x_pu\").alias(\"x\"),\n",
    "    c(\"b_pu\").alias(\"b\"),\n",
    "    c(\"start\").alias(\"timestamp\"),\n",
    "    pl.lit(heartbeat).alias(\"heartbeat\"),\n",
    "    pl.lit(SCADA).alias(\"source_fk\"),  # ??? why or why not ?\n",
    ").with_columns(pl.lit(0.0).alias(col) for col in [\"g\", \"r0\", \"x0\", \"b0\", \"g0\"])\n",
    "\n",
    "new_tables_pl: dict[str, pl.DataFrame] = {\n",
    "    \"Resource\": branch,\n",
    "    \"Equipment\": branch,\n",
    "    \"Branch\": branch,\n",
    "    \"BranchParameterEvent\": branch_parameter_event,\n",
    "}\n",
    "changes_schema = add_table_to_changes_schema(\n",
    "    schema=changes_schema, new_tables_pl=new_tables_pl, raw_table_name=\"branch\"\n",
    ")\n",
    "changes_schema = generate_connectivity_table(\n",
    "    changes_schema=changes_schema, eq_table=branch, raw_data_table=\"branch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_install_date: datetime = datetime(*settings.DEFAULT_INSTALL_DATE, tzinfo=UTC)\n",
    "\n",
    "\n",
    "# Power in PU\n",
    "energy_consumer = df_topology.with_columns(\n",
    "    (\"node_number_\" + c(\"node_number\").cast(pl.String)).alias(\"dso_code\"),\n",
    "    pl.lit(ENERGY_CONSUMER).alias(\"concrete_class\"),\n",
    "    pl.lit(default_install_date).alias(\"start\"),\n",
    "    pl.lit(heartbeat).alias(\"start_heartbeat\"),\n",
    "    pl.lit(\"unknown\").alias(\"profile_type\"),\n",
    "    pl.lit(0).alias(\"rated_p\"),  # Symbol: P_ec_nom, Unit: kW\n",
    "    c(\"cn_fk\")\n",
    "    .pipe(generate_random_uuid)\n",
    "    .alias(\"uuid\"),  # Generate random uuid on a random column\n",
    "    c(\"Pload\").replace(0, None).alias(\"node_with_consumer\"),\n",
    ").drop_nulls(\n",
    "    \"node_with_consumer\"\n",
    ")  # Remove node without consumption\n",
    "new_tables_pl: dict[str, pl.DataFrame] = {\n",
    "    \"Resource\": energy_consumer,\n",
    "    \"Equipment\": energy_consumer,\n",
    "    \"EnergyConsumer\": energy_consumer,\n",
    "}\n",
    "changes_schema = add_table_to_changes_schema(\n",
    "    schema=changes_schema, new_tables_pl=new_tables_pl, raw_table_name=\"energy_consumer\"\n",
    ")\n",
    "changes_schema = generate_connectivity_table(\n",
    "    changes_schema=changes_schema, eq_table=branch, raw_data_table=\"energy_consumer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the uuid of the node to the power data\n",
    "measurement = energy_consumer.select(\n",
    "    c(\"uuid\")\n",
    "    .pipe(generate_random_uuid)\n",
    "    .alias(\n",
    "        \"uuid\"\n",
    "    ),  # Generate random uuid on a column without importance (don't work with pl.lit)\n",
    "    c(\"uuid\").alias(\"resource_fk\"),\n",
    "    pl.lit(heartbeat).alias(\"start_heartbeat\"),\n",
    "    pl.lit(MeasurementClass.SPAN.value).alias(\"concrete_type\"),\n",
    "    pl.lit(MeasurementPhase.ABC.value).alias(\"phase\"),\n",
    "    pl.lit(MeasurementColumn.DOUBLE.value).alias(\"column_type\"),\n",
    "    pl.lit(CONVENTIONAL_METER).alias(\"source_fk\"),\n",
    "    # pl.lit(60*60*24*365).alias(\"default_period\"),\n",
    "    pl.lit(ACTIVE_POWER).alias(\"measurement_type\"),\n",
    "    pl.lit(\"pu\").alias(\"unit_symbol\"),\n",
    "    pl.lit(1).alias(\"unit_multiplier\"),\n",
    "    c(\"Pload\").alias(\"double_value\"),\n",
    ")\n",
    "measurement_span = measurement.with_columns(\n",
    "    c(\"uuid\").alias(\"measurement_fk\"),\n",
    "    c(\"uuid\").pipe(generate_random_uuid).alias(\"uuid\"),\n",
    "    pl.lit(datetime(2022, 1, 1))\n",
    "    .dt.replace_time_zone(time_zone=\"Europe/Zurich\")\n",
    "    .dt.convert_time_zone(time_zone=\"UTC\")\n",
    "    .alias(\"start\"),\n",
    "    pl.lit(datetime(2023, 1, 1))\n",
    "    .dt.replace_time_zone(time_zone=\"Europe/Zurich\")\n",
    "    .dt.convert_time_zone(time_zone=\"UTC\")\n",
    "    .alias(\"end\"),\n",
    ")\n",
    "\n",
    "new_tables_pl: dict[str, pl.DataFrame] = {\n",
    "    \"Measurement\": measurement,\n",
    "    \"MeasurementSpan\": measurement_span,\n",
    "}\n",
    "changes_schema = add_table_to_changes_schema(\n",
    "    schema=changes_schema, new_tables_pl=new_tables_pl, raw_table_name=\"meter_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reactive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the uuid of the node to the power data\n",
    "measurement = energy_consumer.select(\n",
    "    c(\"uuid\")\n",
    "    .pipe(generate_random_uuid)\n",
    "    .alias(\n",
    "        \"uuid\"\n",
    "    ),  # Generate random uuid on a column without importance (don't work with pl.lit)\n",
    "    c(\"uuid\").alias(\"resource_fk\"),\n",
    "    pl.lit(heartbeat).alias(\"start_heartbeat\"),\n",
    "    pl.lit(MeasurementClass.SPAN.value).alias(\"concrete_type\"),\n",
    "    pl.lit(MeasurementPhase.ABC.value).alias(\"phase\"),\n",
    "    pl.lit(MeasurementColumn.DOUBLE.value).alias(\"column_type\"),\n",
    "    pl.lit(CONVENTIONAL_METER).alias(\"source_fk\"),\n",
    "    # pl.lit(60*60*24*365).alias(\"default_period\"),\n",
    "    pl.lit(REACTIVE_POWER).alias(\"measurement_type\"),\n",
    "    pl.lit(\"pu\").alias(\"unit_symbol\"),\n",
    "    pl.lit(1).alias(\"unit_multiplier\"),\n",
    "    c(\"Qload\").alias(\"double_value\"),\n",
    ")\n",
    "measurement_span = measurement.with_columns(\n",
    "    c(\"uuid\").alias(\"measurement_fk\"),\n",
    "    c(\"uuid\").pipe(generate_random_uuid).alias(\"uuid\"),\n",
    "    pl.lit(datetime(2022, 1, 1))\n",
    "    .dt.replace_time_zone(time_zone=\"Europe/Zurich\")\n",
    "    .dt.convert_time_zone(time_zone=\"UTC\")\n",
    "    .alias(\"start\"),\n",
    "    pl.lit(datetime(2023, 1, 1))\n",
    "    .dt.replace_time_zone(time_zone=\"Europe/Zurich\")\n",
    "    .dt.convert_time_zone(time_zone=\"UTC\")\n",
    "    .alias(\"end\"),\n",
    ")\n",
    "\n",
    "new_tables_pl: dict[str, pl.DataFrame] = {\n",
    "    \"Measurement\": measurement,\n",
    "    \"MeasurementSpan\": measurement_span,\n",
    "}\n",
    "changes_schema = add_table_to_changes_schema(\n",
    "    schema=changes_schema, new_tables_pl=new_tables_pl, raw_table_name=\"meter_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to take only switch, connection_type == 3\n",
    "switch = linedata_distflow.filter(c(\"connection_type\") == 3).select(\n",
    "    (\"line_\" + c(\"line_number\").cast(pl.String)).alias(\"dso_code\"),\n",
    "    pl.lit(SWITCH).alias(\"concrete_class\"),\n",
    "    pl.lit(default_install_date).alias(\"start\"),\n",
    "    pl.lit(heartbeat).alias(\"start_heartbeat\"),\n",
    "    pl.lit(switch_state).alias(\"normal_open\"),\n",
    "    pl.lit(switch_type).alias(\"type\"),\n",
    "    pl.lit(switch_command).alias(\"command\"),\n",
    "    # Generate uuid for each terminal of branch with node uuid\n",
    "    c(\"node_from\").replace_strict(connectivity_node, default=None).alias(\"t1\"),\n",
    "    c(\"node_to\").replace_strict(connectivity_node, default=None).alias(\"t2\"),\n",
    "    # Need column name for validation of the schema\n",
    "    pl.lit(None).alias(\"t1_container_fk\"),\n",
    "    pl.lit(None).alias(\"t2_container_fk\"),\n",
    "    c(\"line_number\").pipe(generate_uuid_col, added_string=SWITCH).alias(\"uuid\"),\n",
    ")\n",
    "new_tables_pl: dict[str, pl.DataFrame] = {\n",
    "    \"Resource\": switch,\n",
    "    \"Equipment\": switch,\n",
    "    \"Switch\": switch,\n",
    "}\n",
    "changes_schema = add_table_to_changes_schema(\n",
    "    schema=changes_schema, new_tables_pl=new_tables_pl, raw_table_name=\"switch\"\n",
    ")\n",
    "changes_schema = generate_connectivity_table(\n",
    "    changes_schema=changes_schema, eq_table=switch, raw_data_table=\"switch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-03-27 23:00:00+00:00'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin time of the data from matlab (from main_FC.ipynb before)\n",
    "str(datetime(2020, 4, 4, 23, 00, 0, 0, UTC) - dt.timedelta(hours=192))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heartbeat',\n",
       " 'resource',\n",
       " 'equipment',\n",
       " 'terminal',\n",
       " 'busbar_section',\n",
       " 'branch',\n",
       " 'branch_parameter_event',\n",
       " 'geo_event',\n",
       " 'switch',\n",
       " 'switch_event',\n",
       " 'transformer',\n",
       " 'transformer_end',\n",
       " 'transformer_parameter_event',\n",
       " 'tap',\n",
       " 'tap_event',\n",
       " 'bess',\n",
       " 'energy_consumer',\n",
       " 'external_network',\n",
       " 'generating_unit',\n",
       " 'container',\n",
       " 'client',\n",
       " 'substation',\n",
       " 'base_voltage',\n",
       " 'connectivity_node',\n",
       " 'connectivity',\n",
       " 'measurement',\n",
       " 'measurement_point',\n",
       " 'measurement_span']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changes_schema.connectivity\n",
    "# changes_schema.measurement[\"resource_fk\"][0]\n",
    "# changes_schema.branch.filter(c(\"uuid\") == \"df941fce-ceda-5874-ab63-5c8af9bec38b\")\n",
    "# changes_schema.connectivity.filter(\n",
    "#     c(\"cn_fk\").is_in(changes_schema.measurement[\"resource_fk\"])\n",
    "# )\n",
    "# changes_schema.energy_consumer.join(changes_schema.resource, on=\"uuid\", how=\"inner\")\n",
    "list(changes_schema.__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data to changes schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 14)\n",
      "┌──────────┬────────────┬────────┬───────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
      "│ dso_code ┆ current_li ┆ r_pu   ┆ x_pu      ┆ … ┆ t1         ┆ t2         ┆ t1_contai ┆ t2_contai │\n",
      "│ ---      ┆ mit        ┆ ---    ┆ ---       ┆   ┆ ---        ┆ ---        ┆ ner_fk    ┆ ner_fk    │\n",
      "│ str      ┆ ---        ┆ f64    ┆ f64       ┆   ┆ str        ┆ str        ┆ ---       ┆ ---       │\n",
      "│          ┆ f64        ┆        ┆           ┆   ┆            ┆            ┆ null      ┆ null      │\n",
      "╞══════════╪════════════╪════════╪═══════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
      "│ line_5   ┆ 0.024942   ┆ 0.0775 ┆ 0.0451875 ┆ … ┆ dbd2411e-1 ┆ ba84d70a-8 ┆ null      ┆ null      │\n",
      "│          ┆            ┆        ┆           ┆   ┆ e87-5956-8 ┆ 0d7-590e-b ┆           ┆           │\n",
      "│          ┆            ┆        ┆           ┆   ┆ 6d9-d69ee7 ┆ 112-f9c4b5 ┆           ┆           │\n",
      "│          ┆            ┆        ┆           ┆   ┆ …          ┆ …          ┆           ┆           │\n",
      "└──────────┴────────────┴────────┴───────────┴───┴────────────┴────────────┴───────────┴───────────┘\n",
      "shape: (2, 1)\n",
      "┌─────────────────────────────────┐\n",
      "│ eq_fk                           │\n",
      "│ ---                             │\n",
      "│ str                             │\n",
      "╞═════════════════════════════════╡\n",
      "│ c33afba9-0379-5d6a-9ca1-743cf7… │\n",
      "│ c33afba9-0379-5d6a-9ca1-743cf7… │\n",
      "└─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# energy_consumer.filter(c(\"node_number\") == 5)\n",
    "print(branch.filter(c(\"dso_code\") == \"line_5\"))\n",
    "print(\n",
    "    changes_schema.terminal.select(c(\"eq_fk\")).filter(\n",
    "        c(\"eq_fk\") == \"c33afba9-0379-5d6a-9ca1-743cf7c3512d\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_schema.terminal.select(c(\"eq_fk\")).filter(\n",
    "    c(\"eq_fk\") == \"c33afba9-0379-5d6a-9ca1-743cf7c3512d\"\n",
    ")\n",
    "changes_schema.connectivity.with_columns(\n",
    "    c(\"cn_fk\").is_unique().alias(\"unique\")\n",
    ")  # Give true for the slack node...\n",
    "test2 = changes_schema.connectivity.filter(\n",
    "    c(\"cn_fk\").is_first_distinct() == True\n",
    ")  # Give true for the slack node..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_slack_sq = pow(parameter_distflow[\"Vslack\"][0], 2)\n",
    "test = changes_schema.connectivity  # .filter(c(\"side\") == \"t1\")\n",
    "# line_data\n",
    "# \"downstream\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "# \"upstream\": [None, 1, 2, 1, 4, 4, 4, 6],\n",
    "# \"P\": [0, 1, 2, 1, 4, 3, 6, 5],\n",
    "# \"F\": [0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "# \"p_line\": [0] * 8,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1459228918.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[151], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    dist_flow_df : pl.DataFrame =\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dist_flow_df : pl.DataFrame = \n",
    "iteration = 0\n",
    "# parameter_distflow\n",
    "# ((norm(Vnode_sq(:,2) - Vnode_sq(:,1)) > tol  && iteration < maxIteration))\n",
    "tol = parameter_distflow[\"tol\"][0]\n",
    "max_iteration = parameter_distflow[\"maxIteration\"][0]\n",
    "\n",
    "\n",
    "x = \n",
    "while x < tol and iteration < max_iteration:\n",
    "    print(iteration)\n",
    "    iteration += 1\n",
    "# Qload_augmented = Qload - Bnode .* Vnode_sq(:,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8, 6)\n",
      "┌────────────┬──────────┬─────┬─────┬────────┬─────┐\n",
      "│ downstream ┆ upstream ┆ P   ┆ F   ┆ p_line ┆ lv  │\n",
      "│ ---        ┆ ---      ┆ --- ┆ --- ┆ ---    ┆ --- │\n",
      "│ i64        ┆ i64      ┆ i64 ┆ f64 ┆ f64    ┆ i64 │\n",
      "╞════════════╪══════════╪═════╪═════╪════════╪═════╡\n",
      "│ 3          ┆ 2        ┆ 2   ┆ 0.1 ┆ 2.2    ┆ 0   │\n",
      "│ 5          ┆ 4        ┆ 4   ┆ 0.1 ┆ 4.4    ┆ 0   │\n",
      "│ 7          ┆ 4        ┆ 6   ┆ 0.1 ┆ 6.6    ┆ 0   │\n",
      "│ 8          ┆ 6        ┆ 5   ┆ 0.1 ┆ 5.5    ┆ 0   │\n",
      "│ 2          ┆ 1        ┆ 1   ┆ 0.1 ┆ 3.52   ┆ 1   │\n",
      "│ 6          ┆ 4        ┆ 3   ┆ 0.1 ┆ 9.35   ┆ 1   │\n",
      "│ 4          ┆ 1        ┆ 1   ┆ 0.1 ┆ 23.485 ┆ 2   │\n",
      "│ 1          ┆ null     ┆ 0   ┆ 0.0 ┆ 27.005 ┆ 3   │\n",
      "└────────────┴──────────┴─────┴─────┴────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "def sum_downstream_power(col: pl.Expr, df: pl.DataFrame):\n",
    "    return col.map_elements(\n",
    "        lambda x: df.filter(c(\"upstream\") == x)[\"p_line\"].sum(), return_dtype=pl.Float64\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_line_power(df: pl.DataFrame):\n",
    "    return (c(\"downstream\").pipe(sum_downstream_power, df=df) + c(\"P\")) * (1 + c(\"F\"))\n",
    "\n",
    "\n",
    "def sum_power(df: pl.DataFrame, lv: int):\n",
    "\n",
    "    return df.with_columns(\n",
    "        pl.when(c(\"lv\") == lv)\n",
    "        .then(calculate_line_power(df=df))\n",
    "        .otherwise(c(\"p_line\"))\n",
    "        .alias(\"p_line\")\n",
    "    )\n",
    "\n",
    "\n",
    "# UP Use for each powerflow\n",
    "# Down Use only one time\n",
    "def get_node_level(G: nx.DiGraph) -> dict:\n",
    "    level_mapping: dict = {}\n",
    "    for node in reversed(list(nx.topological_sort(G))):\n",
    "        if not len(list(G.successors(node))):\n",
    "            level_mapping[node] = 0\n",
    "        else:\n",
    "            level_mapping[node] = max(level_mapping[n] for n in G.successors(node)) + 1\n",
    "    return level_mapping\n",
    "\n",
    "\n",
    "line_data: pl.DataFrame = pl.DataFrame(\n",
    "    {\n",
    "        \"downstream\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        \"upstream\": [None, 1, 2, 1, 4, 4, 4, 6],\n",
    "        \"P\": [0, 1, 2, 1, 4, 3, 6, 5],\n",
    "        \"F\": [0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "        \"p_line\": [0] * 8,\n",
    "    }\n",
    ")\n",
    "\n",
    "grid = nx.DiGraph()\n",
    "\n",
    "_ = line_data.drop_nulls(subset=\"upstream\").with_columns(\n",
    "    pl.struct(c(\"upstream\"), c(\"downstream\")).map_elements(\n",
    "        lambda x: grid.add_edge(x[\"upstream\"], x[\"downstream\"]), return_dtype=pl.Struct\n",
    "    )\n",
    ")\n",
    "level_mapping: dict = get_node_level(G=grid)\n",
    "line_data = line_data.with_columns(\n",
    "    c(\"downstream\").replace_strict(level_mapping, default=None).alias(\"lv\")\n",
    ")\n",
    "\n",
    "for i in range(line_data[\"lv\"].max() + 1):\n",
    "    line_data = sum_power(df=line_data, lv=i)\n",
    "\n",
    "print(line_data.sort(\"lv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
